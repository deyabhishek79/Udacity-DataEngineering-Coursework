{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP TABLE IF EXISTS staging_events\n",
      "DROP TABLE IF EXISTS staging_songs\n",
      "DROP TABLE IF EXISTS songplay\n",
      "DROP TABLE IF EXISTS users\n",
      "DROP TABLE IF EXISTS songs\n",
      "DROP TABLE IF EXISTS artists\n",
      "DROP TABLE IF EXISTS time\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "import psycopg2\n",
    "from sql_queries import create_table_queries, drop_table_queries\n",
    "\n",
    "\n",
    "def drop_tables(cur, conn):\n",
    "    for query in drop_table_queries:\n",
    "        print(query)\n",
    "        cur.execute(query)\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "def create_tables(cur, conn):\n",
    "    for query in create_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "def main():\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('dwh.cfg')\n",
    "\n",
    "    conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    drop_tables(cur, conn)\n",
    "    create_tables(cur, conn)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    copy staging_events from 's3://udacity-dend/log_data'\n",
      "    credentials 'aws_iam_role=arn:aws:iam::110255064301:role/myRedshiftRole'\n",
      "    region 'us-west-2' \n",
      "    compupdate off \n",
      "    format as JSON 's3://udacity-dend/log_json_path.json'\n",
      "\n",
      "\n",
      "    copy staging_songs from 's3://udacity-dend/song_data'\n",
      "    credentials 'aws_iam_role=arn:aws:iam::110255064301:role/myRedshiftRole'\n",
      "    region 'us-west-2' \n",
      "    compupdate off\n",
      "    JSON 'auto'\n",
      "    \n",
      "\n",
      "    INSERT INTO songplays (start_time, user_id, level, song_id, \n",
      "                            artist_id, session_id, location, user_agent) \n",
      "    SELECT DISTINCT \n",
      "        events.ts, \n",
      "        events.user_id, \n",
      "        events.user_level,\n",
      "        songs.song_id,\n",
      "        songs.artist_id,\n",
      "        events.session_id,\n",
      "        events.location,\n",
      "        events.user_agent\n",
      "    FROM staging_events as events, staging_songs as songs\n",
      "    WHERE events.page = 'NextSong'\n",
      "    AND events.title = songs.title\n",
      "    AND user_id NOT IN (SELECT DISTINCT songs.user_id FROM songplays as songs WHERE songs.user_id = user_id\n",
      "                       AND songs.start_time = start_time AND songs.session_id = session_id )\n",
      "\n",
      "\n",
      "    INSERT INTO users (user_id, first_name, last_name, gender, level)\n",
      "    \n",
      "    SELECT DISTINCT\n",
      "        events.user_id,\n",
      "        events.first_name,\n",
      "        events.last_name,\n",
      "        events.gender,\n",
      "        events.user_level\n",
      "    FROM staging_events as events\n",
      "    WHERE events.page = 'NextSong'\n",
      "    AND events.user_id NOT IN (SELECT DISTINCT user_id FROM users)\n",
      "\n",
      "\n",
      "    INSERT INTO songs (song_id, title, artist_id, year, duration)\n",
      "    \n",
      "    SELECT DISTINCT \n",
      "        songs.song_id,\n",
      "        songs.title,\n",
      "        songs.artist_id,\n",
      "        songs.year,\n",
      "        songs.duration\n",
      "    FROM staging_songs as songs\n",
      "    WHERE songs.song_id NOT IN (SELECT DISTINCT song_id FROM songs)\n",
      "\n",
      "\n",
      "    INSERT INTO artists (artist_id, name, location, latitude, longitude)\n",
      "    \n",
      "    SELECT DISTINCT \n",
      "        songs.artist_id, \n",
      "        songs.title,\n",
      "        songs.artist_location,\n",
      "        songs.artist_latitude,\n",
      "        songs.artist_longitude\n",
      "    FROM staging_songs as songs\n",
      "    WHERE songs.artist_id NOT IN (SELECT DISTINCT artist_id FROM artists)\n",
      "\n",
      "\n",
      "    INSERT INTO time (start_time, hour, day, week, month, year, weekday)\n",
      "    \n",
      "    SELECT \n",
      "        start_time,\n",
      "        EXTRACT(hr from start_time) AS hour,\n",
      "        EXTRACT(d from start_time) AS day,\n",
      "        EXTRACT(w from start_time) AS week,\n",
      "        EXTRACT(mon from start_time) AS month,\n",
      "        EXTRACT(yr from start_time) AS year, \n",
      "        EXTRACT(weekday from start_time) AS weekday \n",
      "    FROM (\n",
      "    \tSELECT DISTINCT  TIMESTAMP 'epoch' + ts/1000 *INTERVAL '1 second' as start_time \n",
      "        FROM staging_events s     \n",
      "    )\n",
      "    WHERE start_time NOT IN (SELECT DISTINCT start_time FROM time)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "import psycopg2\n",
    "from sql_queries import copy_table_queries, insert_table_queries\n",
    "\n",
    "\n",
    "def load_staging_tables(cur, conn):\n",
    "    for query in copy_table_queries:\n",
    "        print(query)\n",
    "        cur.execute(query)\n",
    "        conn.commit()\n",
    "\n",
    "def insert_tables(cur, conn):\n",
    "    for query in insert_table_queries:\n",
    "        print(query)\n",
    "        cur.execute(query)\n",
    "        conn.commit()\n",
    "\n",
    "def main():\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('dwh.cfg')\n",
    "\n",
    "    conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    load_staging_tables(cur, conn)\n",
    "    insert_tables(cur, conn)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
